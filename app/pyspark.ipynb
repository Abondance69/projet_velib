{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca00f18b-127d-4e16-8d4f-6d132b7c6e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19655b11-b533-4c91-8fc8-1b0d0d11ff34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ DÃ©marrage du test MongoDB...\n",
      "âœ… Session Spark crÃ©Ã©e\n",
      "ðŸ“Š DataFrame Ã  Ã©crire :\n",
      "+---------+-----+\n",
      "|     name|bikes|\n",
      "+---------+-----+\n",
      "|Station A|   10|\n",
      "|Station B|    5|\n",
      "+---------+-----+\n",
      "\n",
      "ðŸ’¾ Ã‰criture dans MongoDB...\n",
      "âœ… Ã‰criture terminÃ©e !\n",
      "ðŸ“– Lecture depuis MongoDB...\n",
      "+--------------------+-----+---------+----+\n",
      "|                 _id|bikes|     name|test|\n",
      "+--------------------+-----+---------+----+\n",
      "|693942fc94e468ae5...| null|     null|   1|\n",
      "|693945bab8c0f67f8...|    5|Station B|null|\n",
      "|693945bab16eb248d...|   10|Station A|null|\n",
      "|693946840ef8fc47b...|    5|Station B|null|\n",
      "|69394684ccce461a2...|   10|Station A|null|\n",
      "|69398b1e24763c6c1...|    5|Station B|null|\n",
      "|69398b1e24763c6c1...|   10|Station A|null|\n",
      "+--------------------+-----+---------+----+\n",
      "\n",
      "ðŸŽ‰ Test Spark â†” MongoDB OK si tu vois les lignes !\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸš€ DÃ©marrage du test MongoDB...\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# 1) CrÃ©er une nouvelle session Spark AVEC le bon connecteur\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"mongo-test\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .config(\n",
    "        \"spark.jars.packages\",\n",
    "        \"org.mongodb.spark:mongo-spark-connector_2.12:10.3.0\"\n",
    "    )\n",
    "    # URI pour LECTURE\n",
    "    .config(\n",
    "        \"spark.mongodb.read.connection.uri\",\n",
    "        \"mongodb://admin:pwd@mongodb-ipssi:27017\"\n",
    "    )\n",
    "    # URI pour Ã‰CRITURE\n",
    "    .config(\n",
    "        \"spark.mongodb.write.connection.uri\",\n",
    "        \"mongodb://admin:pwd@mongodb-ipssi:27017\"\n",
    "    )\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(\"âœ… Session Spark crÃ©Ã©e\")\n",
    "\n",
    "# 2) Petit DataFrame de test\n",
    "data = [(\"Station A\", 10), (\"Station B\", 5)]\n",
    "df = spark.createDataFrame(data, [\"name\", \"bikes\"])\n",
    "\n",
    "print(\"ðŸ“Š DataFrame Ã  Ã©crire :\")\n",
    "df.show()\n",
    "\n",
    "# 3) Ã‰CRITURE dans MongoDB (DB=admin, collection=test_collection)\n",
    "print(\"ðŸ’¾ Ã‰criture dans MongoDB...\")\n",
    "\n",
    "df.write \\\n",
    "    .format(\"mongodb\") \\\n",
    "    .option(\"database\", \"admin\") \\\n",
    "    .option(\"collection\", \"test_collection\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()\n",
    "\n",
    "print(\"âœ… Ã‰criture terminÃ©e !\")\n",
    "\n",
    "# 4) LECTURE depuis MongoDB pour vÃ©rifier\n",
    "print(\"ðŸ“– Lecture depuis MongoDB...\")\n",
    "\n",
    "df_read = (\n",
    "    spark.read\n",
    "    .format(\"mongodb\")\n",
    "    .option(\"database\", \"admin\")\n",
    "    .option(\"collection\", \"test_collection\")\n",
    "    .load()\n",
    ")\n",
    "\n",
    "df_read.show()\n",
    "print(\"ðŸŽ‰ Test Spark â†” MongoDB OK si tu vois les lignes !\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
